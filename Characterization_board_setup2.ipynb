{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from scipy.stats import linregress \n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.ticker as ticker\n",
    "from scipy.odr import ODR, Model, Data, RealData\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First method for finding the saturation value. Compares i with i+1 at a certain level in %\n",
    "def find_saturation_value(column_data):\n",
    "    for i in range(len(column_data) - 1):\n",
    "        if abs(column_data.iloc[i] - column_data.iloc[i + 1]) <= 0.1 * abs(column_data.iloc[i]):\n",
    "            saturation = column_data.iloc[i]\n",
    "            break\n",
    "        else:\n",
    "            saturation = None\n",
    "    return saturation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "lowLevel_plot = True \n",
    "highLevel_plot = True\n",
    "verbose = True\n",
    "pedestal_plot = True\n",
    "fit = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_saturation_from_derivate(T):\n",
    "        \n",
    "        T.sort_values(by=['meanADC'])\n",
    "        # Extract x and y values\n",
    "        x = T['meanRefPD'].values\n",
    "        y = T['meanADC'].values\n",
    "\n",
    "        # Compute the first derivative using central differences\n",
    "        dy_dx = np.gradient(y, x)\n",
    "\n",
    "        # Add the derivative to the DataFrame\n",
    "        T['dy_dx'] = dy_dx\n",
    "        #print(T['dy_dx'])\n",
    "        \n",
    "        # Define a threshold for identifying the plateau\n",
    "        threshold = 0.001\n",
    "\n",
    "        # Identify indices where dy_dx is not flat\n",
    "        #non_flat_indices_aux = np.where(np.abs(dy_dx) >= threshold)[0]\n",
    "\n",
    "        # Get some extra distance to be sure that there is a reduced number of flat indices\n",
    "        #non_flat_indices = non_flat_indices_aux[:-5]\n",
    "\n",
    "\n",
    "        flat_indices = np.where(np.abs(dy_dx) < threshold)[0]\n",
    "        if flat_indices.size > 0:\n",
    "                # Find the index and shift it by two for safety\n",
    "                first_flat_index = flat_indices[0] \n",
    "                satADC=y[first_flat_index]\n",
    "                safe_index = first_flat_index -2\n",
    "                T_non_flat = T.iloc[:safe_index]\n",
    "        else:\n",
    "                satADC=-1\n",
    "                T_non_flat = T\n",
    "        \n",
    "        #print(satADC)\n",
    "        # Extract the corresponding rows\n",
    "        #T_non_flat = T.iloc[non_flat_indices]\n",
    "        \n",
    "        return T_non_flat, satADC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ObtainMeanAndStd(mean_values,err_values):\n",
    "    safe_stderr = np.where(err_values.values == 0, 1e-10, err_values.values)\n",
    "    weights = 1 / np.array(safe_stderr)**2\n",
    "    weighted_mean = np.sum(weights * mean_values) / np.sum(weights)\n",
    "    weighted_mean_error = np.sqrt(1 / np.sum(weights))\n",
    "    weighted_variance = np.sum(weights * (mean_values - weighted_mean)**2) / np.sum(weights)\n",
    "    weighted_std_dev = np.sqrt(weighted_variance)\n",
    "    return weighted_mean, weighted_std_dev\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ADC_analysis(folder_path,dataset_number,output_path,output_path_lowlevel,datetest,boardname):\n",
    "\n",
    "    outputpath = f\"{output_path}\"\n",
    "    outputpath_lowlevel = f\"{output_path_lowlevel}\"\n",
    "\n",
    "    #sensorsID = ['0.0','0.1','0.2','0.3','1.0','1.1','1.2','1.3','2.0','2.1','2.2','2.3','3.0','3.1','3.2','3.3','4.0','4.1','4.2','4.3']\n",
    "    #sensorsID = ['0.0','0.1','1.0','1.1','2.0','2.1','3.0','3.1','4.0','4.1']\n",
    "    sensorsID = ['0.2','0.3','1.2','1.3','2.2','2.3','3.2','3.3','4.2','4.3']\n",
    "    #sensorsID = ['1.0', '4.0']\n",
    "    wavelength = ['1064','532']\n",
    "   \n",
    "    if not os.path.exists(outputpath_lowlevel):\n",
    "        os.makedirs(outputpath_lowlevel)\n",
    "        os.makedirs(outputpath)\n",
    "        print(f\"Directory '{outputpath_lowlevel}' created.\")\n",
    "\n",
    "    if not os.path.exists(outputpath):\n",
    "        os.makedirs(outputpath)\n",
    "        print(f\"Directory '{outputpath}' created.\")\n",
    "\n",
    "    for wl in wavelength:\n",
    "        pedestalsADC = []\n",
    "        pedestalsADC_stderr = []\n",
    "        pedestalsRefPD = []\n",
    "        pedestalsRefPD_stderr = []\n",
    "        slopes = []\n",
    "        intercepts= []\n",
    "        rCoes = []\n",
    "        slopes_stderr = []\n",
    "        intercepts_stderr = []\n",
    "        saturationADCs = []\n",
    "        if wl== '532':\n",
    "        # Rename DataFrame columns\n",
    "            strg_L = 'Laser Current (mA)'\n",
    "            #temp = '20'\n",
    "        elif wl == '1064':\n",
    "            strg_L = 'Laser Power (mW)'\n",
    "            #temp = '25'\n",
    "\n",
    "        for l in sensorsID:\n",
    "            sensorID=l\n",
    "            pedestal_list = []\n",
    "            main_list = []\n",
    "            for number in np.arange(1,dataset_number+1):\n",
    "                filename = f'{folder_path}/{datetest}_{boardname}_{sensorID}_{wl}_{number}.txt'\n",
    "                # Read the first line as a separate DataFrame\n",
    "                df = pd.read_csv(filename, sep=\"\\t\", header=None)\n",
    "                \n",
    "                # Split the first row into a separate DataFrame\n",
    "                first_row = df.iloc[[0]]  # Select the first row as a DataFrame\n",
    "                last_row = df.iloc[[-1]]\n",
    "                pedestal_list.append(first_row)  # Add the first row to pedestal list\n",
    "                pedestal_list.append(last_row)  # Add the first row to pedestal list\n",
    "\n",
    "                # Get the remaining rows (from the second row onward)\n",
    "                main_data = df.iloc[1:-1]  # Select all rows except the first and last\n",
    "                main_list.append(main_data)  # Add to main data list\n",
    "\n",
    "            # Concatenate the first rows (metadata or header info) and the main data\n",
    "            TP = pd.concat(pedestal_list, ignore_index=True)\n",
    "            T = pd.concat(main_list, ignore_index=True)\n",
    "            TP.columns = ['Date-Hour', 'L', 'TotalSum', 'TotalSquareSum', 'meanRefPD', 'stdRefPD', 'Tem', 'RH', 'TotalCounts']\n",
    "            T.columns = ['Date-Hour', 'L', 'TotalSum', 'TotalSquareSum', 'meanRefPD', 'stdRefPD', 'Tem', 'RH', 'TotalCounts']\n",
    "\n",
    "            meanADC = T['TotalSum']/T['TotalCounts']\n",
    "            stdADC = np.sqrt((T['TotalSquareSum']-T['TotalCounts']*meanADC**2)/(T['TotalCounts']-1))\n",
    "            T['meanADC'] = meanADC\n",
    "            T['stdADC'] = stdADC\n",
    "            \n",
    "            pedestal_meanADC = TP['TotalSum']/TP['TotalCounts']\n",
    "            TP['meanADC'] = pedestal_meanADC\n",
    "            TP['stdADC'] = np.sqrt((TP['TotalSquareSum']-TP['TotalCounts']*pedestal_meanADC**2)/(TP['TotalCounts']-1))\n",
    "\n",
    "            # meanPM = meanADC*0.61e-3 #0.61mV/ADCcount  \n",
    "            # stdPM = stdADC*0.61e-3\n",
    "            # # T['meanPM']=meanPM\n",
    "            # T['stdPM']=stdPM\n",
    "            print(f'Starting the fitting procedure for calibration coefficient for sensorID {sensorID} for laser {wl} nm')\n",
    "            #print(T)\n",
    "            #print(TP)\n",
    "\n",
    "            if fit:\n",
    "                T, saturationADC = find_saturation_from_derivate(T)\n",
    "                #saturationADC=-1\n",
    "                res = linregress(T['meanRefPD'], T['meanADC'])\n",
    "                \n",
    "                slopes.append(res.slope)\n",
    "                intercepts.append(res.intercept)\n",
    "                rCoes.append(res.rvalue)\n",
    "                slopes_stderr.append(res.stderr)\n",
    "                intercepts_stderr.append(res.intercept_stderr)\n",
    "                saturationADCs.append(saturationADC)\n",
    "            \n",
    "            pedestalsADC_wmean, pedestalsADC_wstderr = ObtainMeanAndStd(TP['meanADC'],TP['stdADC'])\n",
    "            pedestalsPD_wmean, pedestalsPD_wstderr = ObtainMeanAndStd(TP['meanRefPD'],TP['stdRefPD'])\n",
    "\n",
    "\n",
    "            pedestalsADC.append(pedestalsADC_wmean)\n",
    "            #sqrt((âˆ‘X^2-N*meanADC^2/(N-1))\n",
    "            pedestalsADC_stderr.append(pedestalsADC_wstderr) # This errors should be added in quadrature\n",
    "            pedestalsRefPD.append(pedestalsPD_wmean) \n",
    "            pedestalsRefPD_stderr.append(pedestalsPD_wstderr)# This errors should be added in quadrature\n",
    "\n",
    "\n",
    "            if(verbose and fit):\n",
    "                print(f'Calibration coefficient found for sensorID {sensorID} for laser {wl} nm = {res.slope} +/- {res.stderr} in ADC/V')\n",
    "\n",
    "            if(lowLevel_plot):\n",
    "                fig = plt.figure(2)\n",
    "                plt.errorbar(T['L'], T['meanADC'], yerr=T['stdADC'], fmt='.', markersize=10, linewidth=1)\n",
    "                plt.ylabel('mean ADC counts')\n",
    "                plt.xlabel(strg_L)\n",
    "                plt.grid()\n",
    "                plt.title(f'Plot sensorID {sensorID}, wavelength {wl} nm')\n",
    "                plt.tight_layout()\n",
    "                plt.savefig(f'{outputpath_lowlevel}/{datetest}_{boardname}_{sensorID}_{wl}_meanADC_L.png',dpi=199)  # Display the current figure\n",
    "                plt.close(fig)\n",
    "\n",
    "                fig = plt.figure(4)\n",
    "                plt.errorbar(T['L'], T['meanRefPD'], yerr=T['stdRefPD'], fmt='.', markersize=10, linewidth=1)\n",
    "                plt.ylabel('Mean ref PD (V)')\n",
    "                plt.xlabel(strg_L)\n",
    "                plt.grid()\n",
    "                plt.title(f'Plot sensorID {sensorID}, wavelength {wl} nm')\n",
    "                plt.tight_layout()\n",
    "                plt.savefig(f'{outputpath_lowlevel}/{datetest}_{boardname}_{sensorID}_{wl}_meanRefPD_L.png',dpi=199)  # Display the current figure\n",
    "                #plt.show()\n",
    "                plt.close(fig)\n",
    "\n",
    "                #the label here are incorrect since meanPM=meanADC*0.61e-3 #0.61mV/ADCcoun. Monica proposed from the baffle paper: \n",
    "                #Voltage/ADCcount =3.3V/2**10=0.00322 V/ADCcount\n",
    "                #4.6 uW/ADCcount*1ADCcount/0.00322V = 1428 uW/V\n",
    "\n",
    "                if fit:\n",
    "                    fig = plt.figure(6)\n",
    "                    plt.errorbar(T['meanRefPD'], T['meanADC'], yerr=T['stdADC'], fmt='.', markersize=10, linewidth=1)\n",
    "                    plt.plot(T['meanRefPD'], res.intercept + res.slope*T['meanRefPD'], 'r', label='fitted line')\n",
    "                    plt.ylabel('Mean ADC counts')\n",
    "                    plt.xlabel('Mean ref PD (V)')\n",
    "                    plt.grid()\n",
    "                    plt.title(f'Plot sensorID {sensorID}, wavelength {wl} nm')\n",
    "                    plt.tight_layout()\n",
    "                    plt.savefig(f'{outputpath_lowlevel}/{datetest}_{boardname}_{sensorID}_{wl}_meanADC_meanRefPD.png',dpi=199)  # Display the current figure\n",
    "                    #plt.show()\n",
    "                    plt.close(fig)\n",
    "            \n",
    "        if(highLevel_plot and fit):\n",
    "                tabdata = pd.DataFrame()\n",
    "                tabdata[\"sensorID\"] = sensorsID\n",
    "                tabdata[\"slope\"] = slopes\n",
    "                tabdata[\"intercept\"] = intercepts\n",
    "                tabdata[\"rCoe\"] = rCoes\n",
    "                tabdata[\"slopes_stderr\"] = slopes_stderr\n",
    "                tabdata[\"intercept_stderr\"] = intercepts_stderr\n",
    "                tabdata[\"saturationADC\"] = saturationADCs\n",
    "                \n",
    "                fig = plt.figure(300)\n",
    "                plt.errorbar(range(len(intercepts)), intercepts,intercepts_stderr, fmt='.',  markersize=10, linewidth=1)\n",
    "                plt.axhline(y=np.mean(intercepts), color='tab:olive', linestyle='-')\n",
    "                plt.fill_between(range(-1,len(intercepts)+1), (np.mean(intercepts)-np.std(intercepts)), (np.mean(intercepts)+np.std(intercepts)), color='tab:olive', alpha=0.2)\n",
    "                plt.title(f'Intercepts at {wl} nm. Value = {np.mean(intercepts):.1f} +- {np.std(intercepts):.1f}')\n",
    "                plt.xlabel('SensorID')\n",
    "                plt.ylabel('ADC counts')\n",
    "                plt.xticks(np.arange(len(intercepts)), sensorsID, rotation=20)\n",
    "                plt.xlim([-1,len(sensorsID)])\n",
    "                plt.grid()\n",
    "                plt.savefig(f'{outputpath}/{datetest}_{boardname}_{wl}_noshade_intercepts.png',dpi=199)  # Display the current figure\n",
    "                plt.close()\n",
    "                \n",
    "                fig = plt.figure(400)\n",
    "                plt.errorbar(range(len(rCoes)), rCoes, fmt='.', markersize=10,linewidth=1)\n",
    "                plt.axhline(y=np.mean(rCoes), color='tab:olive', linestyle='-')\n",
    "                plt.fill_between(range(-1,len(rCoes)+1), (np.mean(rCoes)-np.std(rCoes)), (np.mean(rCoes)+np.std(rCoes)), color='tab:olive', alpha=0.2)\n",
    "                plt.title(f'rCoes at {wl} nm. Value = {np.mean(rCoes):.1f} +- {np.std(rCoes):.1f}')\n",
    "                plt.xlabel('SensorID')\n",
    "                plt.ylabel('')\n",
    "                plt.xticks(np.arange(len(rCoes)), sensorsID, rotation=20)\n",
    "                plt.xlim([-1,len(sensorsID)])\n",
    "                plt.grid()\n",
    "                plt.savefig(f'{outputpath}/{datetest}_{boardname}_{wl}_rcoes.png',dpi=199)  # Display the current figure\n",
    "                plt.close()\n",
    "                \n",
    "                fig = plt.figure(500)\n",
    "                plt.title(f'Saturation ADC at {wl} nm. Value = {np.mean(saturationADCs):.1f} +- {np.std(saturationADCs):.1f}')\n",
    "                plt.plot(range(len(saturationADCs)), saturationADCs,'.')\n",
    "                plt.axhline(y=np.mean(saturationADCs), color='tab:olive', linestyle='-')\n",
    "                plt.fill_between(range(-1,len(saturationADCs)+1), (np.mean(saturationADCs)-np.std(saturationADCs)), (np.mean(saturationADCs)+np.std(saturationADCs)), color='tab:olive', alpha=0.2)\n",
    "                plt.xlabel('SensorID')\n",
    "                plt.ylabel('')\n",
    "                plt.xticks(np.arange(len(saturationADCs)), sensorsID, rotation=20)\n",
    "                plt.xlim([-1,len(sensorsID)])\n",
    "                plt.grid()\n",
    "                plt.savefig(f'{outputpath}/{datetest}_{boardname}_{wl}_saturationADC.png',dpi=199)  # Display the current figure\n",
    "                plt.close()\n",
    "\n",
    "                sensorsID1=sensorsID[:16]\n",
    "                sensorsID2=sensorsID[-4:]\n",
    "                slopes1=slopes[:16]\n",
    "                slopes2=slopes[-4:]\n",
    "                intercepts1=intercepts[:16]\n",
    "                intercepts2=intercepts[-4:]\n",
    "                rCoes1=rCoes[:16]\n",
    "                rCoes2=rCoes[-4:]\n",
    "                slopes_stderr1=slopes_stderr[:16]\n",
    "                slopes_stderr2=slopes_stderr[-4:]\n",
    "                intercepts_stderr1=intercepts_stderr[:16]\n",
    "                intercepts_stderr2=intercepts_stderr[-4:]\n",
    "                saturationADCs1=saturationADCs[:16]\n",
    "                saturationADCs2=saturationADCs[-4:]\n",
    "                \n",
    "                #Uncertainty of Weighted Mean: Precision based on individual measurement uncertainties.\n",
    "                #Intervariability: Variability among the measurements (random error, i.e. embedded systematic uncertainties).\n",
    "                #Purely Systematic Error: Accounts for known or estimated biases in the measurements (temperature/humidity????)\n",
    "\n",
    "                weights1 = 1 / np.array(slopes_stderr1)**2\n",
    "                weighted_mean1 = np.sum(weights1 * slopes1) / np.sum(weights1)\n",
    "                weighted_mean_error1 = np.sqrt(1 / np.sum(weights1))\n",
    "                weighted_variance1 = np.sum(weights1 * (slopes1 - weighted_mean1)**2) / np.sum(weights1)\n",
    "                weighted_std_dev1 = np.sqrt(weighted_variance1)\n",
    "                intervariability1 = np.std(slopes1, ddof=1)  # Standard deviation (sample)\n",
    "                combined_sigma1 = np.sqrt(weighted_std_dev1**2+intervariability1**2)\n",
    "                \n",
    "                weights2 = 1 / np.array(slopes_stderr2)**2\n",
    "                weighted_mean2 = np.sum(weights2 * slopes2) / np.sum(weights2)\n",
    "                weighted_mean_error2 = np.sqrt(1 / np.sum(weights2))\n",
    "                weighted_variance2 = np.sum(weights2 * (slopes2 - weighted_mean2)**2) / np.sum(weights2)\n",
    "                weighted_std_dev2 = np.sqrt(weighted_variance2)\n",
    "                intervariability2 = np.std(slopes2, ddof=1)  # Standard deviation (sample)\n",
    "                combined_sigma2 = np.sqrt(weighted_std_dev2**2+intervariability2**2)\n",
    "\n",
    "                ringwog=[slopes[0],slopes[1],slopes[2],slopes[3],slopes[4],slopes[5],slopes[6],slopes[7],slopes[8],slopes[9],slopes[10],slopes[11],slopes[12],slopes[13],slopes[14],slopes[15]]\n",
    "                ringwg=[slopes[16],slopes[17],slopes[18],slopes[19]]\n",
    "                \n",
    "                meanwog = np.mean(ringwog)\n",
    "                meanwg = np.mean(ringwg)\n",
    "                gain = weighted_mean2/weighted_mean1\n",
    "                deviationwog = np.std(ringwog)\n",
    "                deviationwg = np.std(ringwg)\n",
    "               \n",
    "                gainerror=gain*math.sqrt(weighted_std_dev2/(weighted_mean2**2)+weighted_std_dev1/(weighted_mean1**2))\n",
    "                print('--------------------------------------------------------------------------------------------')\n",
    "                print(f'Mean characterization ring 0-3, {wl} = {meanwog} +- {deviationwog}. The error in percent is: {100*deviationwog/meanwog}$%$')\n",
    "                print(f'Weighted mean characterization ring 0-3, {wl} = {weighted_mean1} +- {weighted_mean_error1}. The error in percent is: {100*weighted_mean_error1/weighted_mean1}$%$')\n",
    "                print(f'Weighted standard deviation (spread): {weighted_std_dev1}')\n",
    "                print(f'Standard deviation of the measurements, intervariability: {intervariability1}')\n",
    "                print(f'Total combined error:{combined_sigma1}')\n",
    "                print(f'=> Weighted characterization ring 0-3, {wl} = {weighted_mean1} +- {combined_sigma1}. The error in percent is: {100*combined_sigma1/weighted_mean1}$%$')\n",
    "\n",
    "                \n",
    "                print(f'Mean characterization ring 4 {wl} = {meanwg} +- {deviationwg}. The error in percent is: {100*deviationwg/meanwg}$%$')\n",
    "                print(f'Weighted mean characterization ring 4, {wl} = {weighted_mean2} +- {weighted_mean_error2}. The error in percent is: {100*weighted_mean_error2/weighted_mean2}$%$')\n",
    "                print(f'Weighted standard deviation (spread): {weighted_std_dev2}')\n",
    "                print(f'Standard deviation of the measurements, intervariability: {intervariability2}')\n",
    "                print(f'Total combined error:{combined_sigma2}')\n",
    "                print(f'=> Weighted characterization ring 4, {wl} = {weighted_mean2} +- {combined_sigma2}. The error in percent is: {100*combined_sigma2/weighted_mean2}$%$')\n",
    "                \n",
    "                print(f\"==> Gain for ring 4 vs. 1-3 from weighted mean,{wl} = {gain} +- {gainerror}. The error in percent is: {100*gainerror/gain}$%$\")\n",
    "\n",
    "                print('--------------------------------------------------------------------------------------------')\n",
    "\n",
    "\n",
    "                fig = plt.figure(101)\n",
    "                plt.errorbar(range(len(slopes1)),slopes1,slopes_stderr1,fmt='.',color='tab:purple',markersize=10,linewidth=1)\n",
    "                plt.axhline(y=weighted_mean1, color='tab:olive', linestyle='-', label='wmean ADC/V')\n",
    "                plt.fill_between(range(-1,len(slopes1)+1), (weighted_mean1-weighted_std_dev1), (weighted_mean1+weighted_std_dev1), color='tab:olive', alpha=0.2, label= '${\\sigma}_{weightStd}$')\n",
    "                plt.fill_between(range(-1,len(slopes1)+1), (weighted_mean1-combined_sigma1), (weighted_mean1+combined_sigma1), color='tab:cyan', alpha=0.2, label= '${\\sigma}_{weightStd} + {\\sigma}_{intervar} $')\n",
    "                # plt.axhline(y=np.mean(slopes1), color='tab:olive', linestyle='-', label='mean ADC/V')\n",
    "                # plt.fill_between(range(-1,len(slopes1)+1), (np.mean(slopes1)-np.std(slopes1)), (np.mean(slopes1)+np.std(slopes1)), color='tab:olive', alpha=0.2)\n",
    "                plt.title(f'Sensors char at {wl} nm. Value =  {weighted_mean1:.1f} +- {combined_sigma1:.1f} ADC/V ({100*combined_sigma1/weighted_mean1:.1f}%)')\n",
    "                plt.xlabel('SensorID')\n",
    "                plt.ylabel('ADC counts/V')\n",
    "                plt.xticks(np.arange(len(slopes1)), sensorsID1, rotation=20)\n",
    "                plt.xlim([-1,len(sensorsID1)]) \n",
    "                plt.grid()\n",
    "                plt.legend()\n",
    "                plt.savefig(f'{outputpath}/{datetest}_{boardname}_{wl}_calibration_0_3.png',dpi=199)  # Display the current figure\n",
    "                plt.close()\n",
    "                \n",
    "                if(lowLevel_plot):\n",
    "\n",
    "                    fig = plt.figure(200)\n",
    "                    plt.errorbar(range(len(slopes_stderr1)), slopes_stderr1, fmt='.',color='tab:purple', markersize=10, linewidth=1)\n",
    "                    plt.axhline(y=np.mean(slopes_stderr1), color='tab:olive', linestyle='-', label='mean ADC/V')\n",
    "                    plt.fill_between(range(-1,len(slopes_stderr1)+1), (np.mean(slopes_stderr1)-np.std(slopes_stderr1)), (np.mean(slopes_stderr1)+np.std(slopes_stderr1)), color='tab:olive', alpha=0.2)\n",
    "                    plt.title(f'Stderr at {wl} nm. Value = {np.mean(slopes_stderr1):.1f} +- {np.std(slopes_stderr1):.1f}')\n",
    "                    plt.xlabel('SensorID')\n",
    "                    plt.ylabel('ADC counts/V')\n",
    "                    plt.xticks(np.arange(len(slopes_stderr1)), sensorsID1, rotation=20)\n",
    "                    plt.xlim([-1,len(sensorsID1)])\n",
    "                    plt.grid()\n",
    "                    plt.savefig(f'{outputpath}/{datetest}_{boardname}_{wl}_calibration_stderrs_0_3.png',dpi=199)  # Display the current figure\n",
    "                    plt.close()\n",
    "\n",
    "                fig = plt.figure(102)\n",
    "                plt.errorbar(range(len(slopes2)), slopes2, slopes_stderr2, fmt='.',color='tab:purple', markersize=10, linewidth=1)\n",
    "                plt.axhline(y=weighted_mean2, color='tab:olive', linestyle='-', label='wmean ADC/V')\n",
    "                plt.fill_between(range(-1,len(slopes2)+1), (weighted_mean2-weighted_std_dev2), (weighted_mean2+weighted_std_dev2), color='tab:olive', alpha=0.2, label= '${\\sigma}_{weightStd} $')\n",
    "                plt.fill_between(range(-1,len(slopes2)+1), (weighted_mean2-combined_sigma2), (weighted_mean2+combined_sigma2), color='tab:cyan', alpha=0.2,label= '${\\sigma}_{weightStd} + {\\sigma}_{intervar} $')\n",
    "                #plt.axhline(y=np.mean(slopes2), color='tab:olive', linestyle='-', label='mean ADC/V')\n",
    "                #plt.fill_between(range(-1,len(slopes2)+1), (np.mean(slopes2)-np.std(slopes2)), (np.mean(slopes2)+np.std(slopes2)), color='tab:olive', alpha=0.2)\n",
    "                plt.title(f'Sensors char at {wl} nm. Value = {weighted_mean2:.1f} +- {combined_sigma2:.1f} ADC/V ({100*combined_sigma2/weighted_mean2:.1f}%)')\n",
    "                plt.xlabel('SensorID')\n",
    "                plt.ylabel('ADC counts/V')\n",
    "                plt.xticks(np.arange(len(slopes2)), sensorsID2, rotation=20)\n",
    "                plt.xlim([-1,len(sensorsID2)]) \n",
    "                plt.grid()\n",
    "                plt.legend()\n",
    "                plt.savefig(f'{outputpath}/{datetest}_{boardname}_{wl}_calibration_4.png',dpi=199)  # Display the current figure\n",
    "                plt.close()\n",
    "                \n",
    "                if(lowLevel_plot):\n",
    "                    fig = plt.figure(200)\n",
    "                    plt.errorbar(range(len(slopes_stderr2)), slopes_stderr2, fmt='.', color='tab:purple', markersize=10, linewidth=1)\n",
    "                    plt.axhline(y=np.mean(slopes_stderr2), color='tab:olive', linestyle='-', label='mean ADC/V')\n",
    "                    plt.fill_between(range(-1,len(slopes_stderr2)+1), (np.mean(slopes_stderr2)-np.std(slopes_stderr2)), (np.mean(slopes_stderr2)+np.std(slopes_stderr2)), color='tab:olive', alpha=0.2)\n",
    "                    plt.title(f'Stderr at {wl} nm. Value = {np.mean(slopes_stderr2):.1f} +- {np.std(slopes_stderr2):.1f}')\n",
    "                    plt.xlabel('SensorID')\n",
    "                    plt.ylabel('ADC counts/V')\n",
    "                    plt.xticks(np.arange(len(slopes_stderr2)), sensorsID2, rotation=20)\n",
    "                    plt.xlim([-1,len(sensorsID2)])\n",
    "                    plt.grid()\n",
    "                    plt.savefig(f'{outputpath}/{datetest}_{boardname}_{wl}_calibration_stderrs_4.png',dpi=199)  # Display the current figure\n",
    "                    plt.close()\n",
    "        if(pedestal_plot):\n",
    "            fig =  plt.figure(11)\n",
    "            plt.errorbar(range(len(pedestalsADC)),pedestalsADC, pedestalsADC_stderr, fmt='.',color='tab:purple', markersize=10, linewidth=1)\n",
    "            plt.xlabel('SensorID')\n",
    "            plt.ylabel('ADC counts')\n",
    "            plt.xticks(range(len(pedestalsADC)), sensorsID, rotation=20)\n",
    "            plt.xlim([-1,len(sensorsID)])\n",
    "            plt.grid()\n",
    "            plt.title(f'Pedestal of the ADC for measurement of {wl} laser')\n",
    "            plt.savefig(f'{outputpath}/{datetest}_{boardname}_{wl}_pedestals_ADC.png',dpi=199)  # Display the current figure\n",
    "            plt.close()\n",
    "            \n",
    "            fig =  plt.figure(12)\n",
    "            plt.errorbar(range(len(pedestalsRefPD)),pedestalsRefPD, pedestalsRefPD_stderr, fmt='.',color='tab:purple', markersize=10, linewidth=1)\n",
    "            plt.xlabel('SensorID')\n",
    "            plt.ylabel('V')\n",
    "            plt.xticks(range(len(pedestalsADC)), sensorsID, rotation=20)\n",
    "            plt.xlim([-1,len(sensorsID)])\n",
    "            plt.grid()\n",
    "            plt.title(f'Pedestals of the PD reference for measurement of {wl} laser')\n",
    "            plt.savefig(f'{outputpath}/{datetest}_{boardname}_{wl}_pedestals_RefPD.png',dpi=199)  # Display the current figure\n",
    "            plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANALYSIS OF THE DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting the fitting procedure for calibration coefficient for sensorID 0.2 for laser 1064 nm\n",
      "Starting the fitting procedure for calibration coefficient for sensorID 0.3 for laser 1064 nm\n",
      "Starting the fitting procedure for calibration coefficient for sensorID 1.2 for laser 1064 nm\n",
      "Starting the fitting procedure for calibration coefficient for sensorID 1.3 for laser 1064 nm\n",
      "Starting the fitting procedure for calibration coefficient for sensorID 2.2 for laser 1064 nm\n",
      "Starting the fitting procedure for calibration coefficient for sensorID 2.3 for laser 1064 nm\n",
      "Starting the fitting procedure for calibration coefficient for sensorID 3.2 for laser 1064 nm\n",
      "Starting the fitting procedure for calibration coefficient for sensorID 3.3 for laser 1064 nm\n",
      "Starting the fitting procedure for calibration coefficient for sensorID 4.2 for laser 1064 nm\n",
      "Starting the fitting procedure for calibration coefficient for sensorID 4.3 for laser 1064 nm\n",
      "Starting the fitting procedure for calibration coefficient for sensorID 0.2 for laser 532 nm\n",
      "Starting the fitting procedure for calibration coefficient for sensorID 0.3 for laser 532 nm\n",
      "Starting the fitting procedure for calibration coefficient for sensorID 1.2 for laser 532 nm\n",
      "Starting the fitting procedure for calibration coefficient for sensorID 1.3 for laser 532 nm\n",
      "Starting the fitting procedure for calibration coefficient for sensorID 2.2 for laser 532 nm\n",
      "Starting the fitting procedure for calibration coefficient for sensorID 2.3 for laser 532 nm\n",
      "Starting the fitting procedure for calibration coefficient for sensorID 3.2 for laser 532 nm\n",
      "Starting the fitting procedure for calibration coefficient for sensorID 3.3 for laser 532 nm\n",
      "Starting the fitting procedure for calibration coefficient for sensorID 4.2 for laser 532 nm\n",
      "Starting the fitting procedure for calibration coefficient for sensorID 4.3 for laser 532 nm\n"
     ]
    }
   ],
   "source": [
    "#ADC_analysis('./Data/setup2/20112024_9R1/data',3,\"./Data/setup2/20112024_9R1/plots\",\"./Data/setup2/20112024_9R1/plots/LowLevel\",'20112024','9R1')\n",
    "#ADC_analysis('./Data/setup2/06022025_1R0/04022025_1R0/data',3,\"./Data/setup2/06022025_1R0/04022025_1R0/plots\",\"./Data/setup2/06022025_1R0/04022025_1R0/plots/LowLevel\",'04022025','1R0')\n",
    "ADC_analysis('./Data/setup2/06022025_1R0/30012025_1R0/data',3,\"./Data/setup2/06022025_1R0/30012025_1R0/plots\",\"./Data/setup2/06022025_1R0/30012025_1R0/plots/LowLevel\",'30012025','1R0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting the fitting procedure for calibration coefficient for sensorID 0.0 for laser 1064 nm\n",
      "Starting the fitting procedure for calibration coefficient for sensorID 0.1 for laser 1064 nm\n",
      "Starting the fitting procedure for calibration coefficient for sensorID 1.0 for laser 1064 nm\n",
      "Starting the fitting procedure for calibration coefficient for sensorID 1.1 for laser 1064 nm\n",
      "Starting the fitting procedure for calibration coefficient for sensorID 2.0 for laser 1064 nm\n",
      "Starting the fitting procedure for calibration coefficient for sensorID 2.1 for laser 1064 nm\n",
      "Starting the fitting procedure for calibration coefficient for sensorID 3.0 for laser 1064 nm\n",
      "Starting the fitting procedure for calibration coefficient for sensorID 3.1 for laser 1064 nm\n",
      "Starting the fitting procedure for calibration coefficient for sensorID 4.0 for laser 1064 nm\n",
      "Starting the fitting procedure for calibration coefficient for sensorID 4.1 for laser 1064 nm\n",
      "Starting the fitting procedure for calibration coefficient for sensorID 0.0 for laser 532 nm\n",
      "Starting the fitting procedure for calibration coefficient for sensorID 0.1 for laser 532 nm\n",
      "Starting the fitting procedure for calibration coefficient for sensorID 1.0 for laser 532 nm\n",
      "Starting the fitting procedure for calibration coefficient for sensorID 1.1 for laser 532 nm\n",
      "Starting the fitting procedure for calibration coefficient for sensorID 2.0 for laser 532 nm\n",
      "Starting the fitting procedure for calibration coefficient for sensorID 2.1 for laser 532 nm\n",
      "Starting the fitting procedure for calibration coefficient for sensorID 3.0 for laser 532 nm\n",
      "Starting the fitting procedure for calibration coefficient for sensorID 3.1 for laser 532 nm\n",
      "Starting the fitting procedure for calibration coefficient for sensorID 4.0 for laser 532 nm\n",
      "Starting the fitting procedure for calibration coefficient for sensorID 4.1 for laser 532 nm\n"
     ]
    }
   ],
   "source": [
    "# Merges dataset up to the number given, fits the data, and the coefficient is obtained \n",
    "ADC_analysis('./Data/setup2/28102024_4L2/data',3,\"./Data/setup2/28102024_4L2/plots\",\"./Data/setup2/28102024_4L2/plots/LowLevel\",'28102024','4L2')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MergeDatasets(folder_path):\n",
    "    # Initialize an empty list to store individual DataFrames\n",
    "    dataframes = []\n",
    "    # Iterate over each file in the folder\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        if file_name.endswith('.txt'):  # Only process .txt files\n",
    "            file_path = os.path.join(folder_path, file_name)\n",
    "            sensor_id = file_name.split('.')[0]\n",
    "\n",
    "            # Read the file into a pandas DataFrame\n",
    "            df = pd.read_csv(file_path, sep='\\t', header=None)\n",
    "            \n",
    "            # Assign the provided column names\n",
    "            df.columns = ['Date-Time', 'Laser_Power', 'Total_Sum', 'Total_Sqr', 'V_Mean', 'Std_V', 'Temp', 'Humidity', 'Total_Counts']\n",
    "            df.loc[:, 'pd_val'] = df['Total_Sum']/df['Total_Counts']\n",
    "            df.loc[:, 'pd_val_norm'] = df['pd_val']/df['V_Mean']\n",
    "            df.loc[:, 'sensor_id'] = sensor_id\n",
    "            \n",
    "            # Append the DataFrame to the list\n",
    "            dataframes.append(df)\n",
    "\n",
    "    # Concatenate all the DataFrames into one\n",
    "    final_df = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "    # Display the first few rows of the concatenated DataFrame\n",
    "    #print(final_df.head())\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Overall_Stability(final_df, columns_to_plot):\n",
    "    # Create a plot for each column\n",
    "    for column in columns_to_plot:\n",
    "        # Calculate mean and variance\n",
    "        mean_value = final_df[column].mean()\n",
    "        std_dev = final_df[column].std()  # Standard deviation\n",
    "        \n",
    "        # Calculate sigma as a percentage of the mean\n",
    "        sigma_percentage = (std_dev / mean_value) * 100 if mean_value != 0 else 0\n",
    "        \n",
    "        # Print mean and sigma (standard deviation)\n",
    "        print(f'{column}:')\n",
    "        print(f'  Mean: {mean_value}')\n",
    "        print(f'  Standard Deviation (Ïƒ): {std_dev}')\n",
    "        print(f'  Standard Deviation as Percentage of Mean: {sigma_percentage}%')\n",
    "        \n",
    "        \n",
    "        # Create a subplot with 2 plots side by side (1 row, 2 columns)\n",
    "        fig, axs = plt.subplots(1, 2, figsize=(15, 6))  # Adjust the figure size as necessary\n",
    "\n",
    "        # Plot the evolution of values (line plot) on the left\n",
    "        axs[0].plot(final_df[column], '.', color='orange')\n",
    "        axs[0].set_title(f'{column} Evolution (Mean: {mean_value:.2f}, Ïƒ%: {sigma_percentage:.2f}%)')\n",
    "        axs[0].set_xlabel('Index (Time Steps)')\n",
    "        axs[0].set_ylabel(column)\n",
    "        axs[0].grid(True)\n",
    "\n",
    "        # Plot the histogram on the right\n",
    "        axs[1].hist(final_df[column], bins=30, edgecolor='black', alpha=0.7)\n",
    "        axs[1].set_title(f'{column} Histogram')\n",
    "        axs[1].set_xlabel(column)\n",
    "        axs[1].set_ylabel('Frequency')\n",
    "        axs[1].grid(True)\n",
    "\n",
    "        # Adjust the layout to prevent overlapping\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        # Show the combined plots\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check overall stability of the main variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = MergeDatasets('./Data/setup2/28102024_4L2/data')\n",
    "# Plot each column except 'Date' and 'Time'\n",
    "columns_to_plot = ['Laser_Power', 'Total_Sum', 'Total_Sqr', 'V_Mean', 'Std_V', 'Temp', 'Humidity', 'Total_Counts']\n",
    "\n",
    "Overall_Stability(datasets,columns_to_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = MergeDatasets('./Data/setup2/20112024_9R1/data')\n",
    "# Plot each column except 'Date' and 'Time'\n",
    "columns_to_plot = ['Laser_Power', 'Total_Sum', 'Total_Sqr', 'V_Mean', 'Std_V', 'Temp', 'Humidity', 'Total_Counts']\n",
    "\n",
    "Overall_Stability(datasets,columns_to_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "readPandas",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
